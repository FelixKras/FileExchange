{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow Intro convolutional_network_Solution.ipynb","version":"0.3.2","provenance":[{"file_id":"18OOpGy7VoO6ArytGko2AHZSHzUUeNKP8","timestamp":1562912719521}]},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jzhecE-Hile_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"fef999e4-c454-46b9-dc44-ce81cd110c5e","executionInfo":{"status":"ok","timestamp":1562919257577,"user_tz":-180,"elapsed":981,"user":{"displayName":"tamir nave","photoUrl":"https://lh3.googleusercontent.com/-8XBDgRJ8BQ8/AAAAAAAAAAI/AAAAAAAACWs/OaIv-sLVA40/s64/photo.jpg","userId":"00122975368542610629"}}},"source":["'''\n","A Convolutional Network implementation example using TensorFlow library.\n","This example is using the MNIST database of handwritten digits\n","(http://yann.lecun.com/exdb/mnist/)\n","\n","Author: Aymeric Damien\n","Project: https://github.com/aymericdamien/TensorFlow-Examples/\n","'''"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nA Convolutional Network implementation example using TensorFlow library.\\nThis example is using the MNIST database of handwritten digits\\n(http://yann.lecun.com/exdb/mnist/)\\n\\nAuthor: Aymeric Damien\\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"YNzzfwgzilfD","colab_type":"code","outputId":"b4dc6885-a942-4282-c2ac-5a750951f7f0","executionInfo":{"status":"ok","timestamp":1562919263012,"user_tz":-180,"elapsed":6406,"user":{"displayName":"tamir nave","photoUrl":"https://lh3.googleusercontent.com/-8XBDgRJ8BQ8/AAAAAAAAAAI/AAAAAAAACWs/OaIv-sLVA40/s64/photo.jpg","userId":"00122975368542610629"}},"colab":{"base_uri":"https://localhost:8080/","height":557}},"source":["import tensorflow as tf\n","\n","# Import MNIST data\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0712 08:14:19.816318 139653525571456 deprecation.py:323] From <ipython-input-2-14aa7db46b75>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","W0712 08:14:19.818411 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","W0712 08:14:19.824415 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","W0712 08:14:20.336291 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0712 08:14:20.861736 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","W0712 08:14:20.865813 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0712 08:14:21.382678 139653525571456 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DTHslsWNilfG","colab_type":"code","colab":{}},"source":["# Parameters\n","learning_rate = 0.001\n","training_iters = 3000000\n","batch_size = 128\n","display_step = 100\n","\n","# Network Parameters\n","n_input = 784 # MNIST data input (img shape: 28*28)\n","n_classes = 10 # MNIST total classes (0-9 digits)\n","# tf Graph input\n","x = tf.placeholder(tf.float32, [None, n_input])\n","y = tf.placeholder(tf.float32, [None, n_classes])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCEN28gqilfI","colab_type":"code","colab":{}},"source":["# Create some wrappers for simplicity\n","def conv2d(x, W, b, strides=1):\n","    # Conv2D wrapper, with bias and relu activation\n","    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n","    x = tf.nn.bias_add(x, b)\n","    return tf.nn.relu(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3XjV6a6NilfL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1d3090f5-68bf-4e98-a4d4-3bf9f4501c83","executionInfo":{"status":"ok","timestamp":1562919344179,"user_tz":-180,"elapsed":87554,"user":{"displayName":"tamir nave","photoUrl":"https://lh3.googleusercontent.com/-8XBDgRJ8BQ8/AAAAAAAAAAI/AAAAAAAACWs/OaIv-sLVA40/s64/photo.jpg","userId":"00122975368542610629"}}},"source":["x_reshaped = tf.reshape(x, shape=[-1, 28, 28, 1])\n","conv1 = conv2d(x_reshaped, tf.Variable(tf.random_normal([10, 10, 1, 3])), tf.Variable(tf.random_normal([3])))\n","conv1_flatten = tf.reshape(conv1, shape=[-1, 19*19*3])\n","fc1 = tf.add(tf.matmul(conv1_flatten, tf.Variable(tf.random_normal([19*19*3, 10]))), tf.Variable(tf.random_normal([10])))\n","pred = fc1 #tf.nn.softmax(fc1)\n","\n","# Define loss and optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)) #sigmoid\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","# Evaluate model\n","correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# Initializing the variables\n","init = tf.global_variables_initializer()\n","\n","# Launch the graph\n","sess=tf.Session()\n","sess.run(init)\n","step = 1\n","# Keep training until reach max iterations\n","while step * batch_size < training_iters:\n","    batch_x, batch_y = mnist.train.next_batch(batch_size)\n","    # Run optimization op (backprop)\n","    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n","    if step % display_step == 0:\n","        # Calculate batch loss and accuracy\n","        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n","        print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n","              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n","              \"{:.5f}\".format(acc)\n","    step += 1\n","print \"Optimization Finished!\"\n","\n","# Calculate accuracy for 256 mnist test images\n","print \"Testing Accuracy:\", \\\n","    sess.run(accuracy, feed_dict={x: mnist.test.images[:256], y: mnist.test.labels[:256]})"],"execution_count":5,"outputs":[{"output_type":"stream","text":["W0712 08:14:21.763818 139653525571456 deprecation.py:323] From <ipython-input-5-ad21a1c45308>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Iter 12800, Minibatch Loss= 105.352249, Training Accuracy= 0.14062\n","Iter 25600, Minibatch Loss= 63.317032, Training Accuracy= 0.35938\n","Iter 38400, Minibatch Loss= 32.574661, Training Accuracy= 0.53906\n","Iter 51200, Minibatch Loss= 29.105057, Training Accuracy= 0.54688\n","Iter 64000, Minibatch Loss= 21.332874, Training Accuracy= 0.60938\n","Iter 76800, Minibatch Loss= 20.022480, Training Accuracy= 0.67969\n","Iter 89600, Minibatch Loss= 15.148023, Training Accuracy= 0.78125\n","Iter 102400, Minibatch Loss= 22.665751, Training Accuracy= 0.66406\n","Iter 115200, Minibatch Loss= 11.666031, Training Accuracy= 0.74219\n","Iter 128000, Minibatch Loss= 11.998309, Training Accuracy= 0.75781\n","Iter 140800, Minibatch Loss= 16.376919, Training Accuracy= 0.72656\n","Iter 153600, Minibatch Loss= 10.753185, Training Accuracy= 0.79688\n","Iter 166400, Minibatch Loss= 11.135790, Training Accuracy= 0.77344\n","Iter 179200, Minibatch Loss= 10.214697, Training Accuracy= 0.78125\n","Iter 192000, Minibatch Loss= 6.427622, Training Accuracy= 0.85938\n","Iter 204800, Minibatch Loss= 14.974844, Training Accuracy= 0.79688\n","Iter 217600, Minibatch Loss= 3.746722, Training Accuracy= 0.89062\n","Iter 230400, Minibatch Loss= 5.118805, Training Accuracy= 0.85156\n","Iter 243200, Minibatch Loss= 5.063696, Training Accuracy= 0.88281\n","Iter 256000, Minibatch Loss= 5.378776, Training Accuracy= 0.87500\n","Iter 268800, Minibatch Loss= 4.242854, Training Accuracy= 0.85156\n","Iter 281600, Minibatch Loss= 5.722741, Training Accuracy= 0.80469\n","Iter 294400, Minibatch Loss= 3.627545, Training Accuracy= 0.86719\n","Iter 307200, Minibatch Loss= 4.758971, Training Accuracy= 0.82812\n","Iter 320000, Minibatch Loss= 2.707941, Training Accuracy= 0.91406\n","Iter 332800, Minibatch Loss= 4.136452, Training Accuracy= 0.85156\n","Iter 345600, Minibatch Loss= 5.214622, Training Accuracy= 0.86719\n","Iter 358400, Minibatch Loss= 7.390066, Training Accuracy= 0.85156\n","Iter 371200, Minibatch Loss= 3.862320, Training Accuracy= 0.88281\n","Iter 384000, Minibatch Loss= 5.290553, Training Accuracy= 0.92969\n","Iter 396800, Minibatch Loss= 3.553278, Training Accuracy= 0.89062\n","Iter 409600, Minibatch Loss= 3.503206, Training Accuracy= 0.89062\n","Iter 422400, Minibatch Loss= 1.000037, Training Accuracy= 0.91406\n","Iter 435200, Minibatch Loss= 6.707105, Training Accuracy= 0.82812\n","Iter 448000, Minibatch Loss= 5.582385, Training Accuracy= 0.89062\n","Iter 460800, Minibatch Loss= 2.291050, Training Accuracy= 0.91406\n","Iter 473600, Minibatch Loss= 3.136336, Training Accuracy= 0.88281\n","Iter 486400, Minibatch Loss= 3.010153, Training Accuracy= 0.87500\n","Iter 499200, Minibatch Loss= 3.584327, Training Accuracy= 0.91406\n","Iter 512000, Minibatch Loss= 2.433291, Training Accuracy= 0.94531\n","Iter 524800, Minibatch Loss= 4.086938, Training Accuracy= 0.91406\n","Iter 537600, Minibatch Loss= 0.724184, Training Accuracy= 0.93750\n","Iter 550400, Minibatch Loss= 2.832597, Training Accuracy= 0.92188\n","Iter 563200, Minibatch Loss= 3.545860, Training Accuracy= 0.89062\n","Iter 576000, Minibatch Loss= 2.228656, Training Accuracy= 0.89844\n","Iter 588800, Minibatch Loss= 2.212593, Training Accuracy= 0.92969\n","Iter 601600, Minibatch Loss= 2.138613, Training Accuracy= 0.90625\n","Iter 614400, Minibatch Loss= 1.307908, Training Accuracy= 0.91406\n","Iter 627200, Minibatch Loss= 2.475549, Training Accuracy= 0.90625\n","Iter 640000, Minibatch Loss= 2.910232, Training Accuracy= 0.89844\n","Iter 652800, Minibatch Loss= 1.793748, Training Accuracy= 0.90625\n","Iter 665600, Minibatch Loss= 1.688382, Training Accuracy= 0.92188\n","Iter 678400, Minibatch Loss= 2.322441, Training Accuracy= 0.89844\n","Iter 691200, Minibatch Loss= 2.502802, Training Accuracy= 0.89062\n","Iter 704000, Minibatch Loss= 0.380731, Training Accuracy= 0.96094\n","Iter 716800, Minibatch Loss= 0.881690, Training Accuracy= 0.93750\n","Iter 729600, Minibatch Loss= 2.219954, Training Accuracy= 0.90625\n","Iter 742400, Minibatch Loss= 1.622164, Training Accuracy= 0.91406\n","Iter 755200, Minibatch Loss= 1.413493, Training Accuracy= 0.92188\n","Iter 768000, Minibatch Loss= 2.001033, Training Accuracy= 0.92188\n","Iter 780800, Minibatch Loss= 3.100841, Training Accuracy= 0.92969\n","Iter 793600, Minibatch Loss= 1.896173, Training Accuracy= 0.90625\n","Iter 806400, Minibatch Loss= 1.575806, Training Accuracy= 0.92969\n","Iter 819200, Minibatch Loss= 1.114035, Training Accuracy= 0.93750\n","Iter 832000, Minibatch Loss= 0.663122, Training Accuracy= 0.95312\n","Iter 844800, Minibatch Loss= 0.391450, Training Accuracy= 0.97656\n","Iter 857600, Minibatch Loss= 0.331135, Training Accuracy= 0.96094\n","Iter 870400, Minibatch Loss= 2.184997, Training Accuracy= 0.91406\n","Iter 883200, Minibatch Loss= 1.029123, Training Accuracy= 0.95312\n","Iter 896000, Minibatch Loss= 1.391172, Training Accuracy= 0.93750\n","Iter 908800, Minibatch Loss= 1.471225, Training Accuracy= 0.93750\n","Iter 921600, Minibatch Loss= 0.770940, Training Accuracy= 0.96094\n","Iter 934400, Minibatch Loss= 3.303011, Training Accuracy= 0.89844\n","Iter 947200, Minibatch Loss= 1.379589, Training Accuracy= 0.88281\n","Iter 960000, Minibatch Loss= 0.782906, Training Accuracy= 0.96875\n","Iter 972800, Minibatch Loss= 0.559682, Training Accuracy= 0.94531\n","Iter 985600, Minibatch Loss= 1.081892, Training Accuracy= 0.96094\n","Iter 998400, Minibatch Loss= 0.378428, Training Accuracy= 0.95312\n","Iter 1011200, Minibatch Loss= 1.106024, Training Accuracy= 0.94531\n","Iter 1024000, Minibatch Loss= 2.026442, Training Accuracy= 0.92188\n","Iter 1036800, Minibatch Loss= 0.990088, Training Accuracy= 0.92969\n","Iter 1049600, Minibatch Loss= 1.547722, Training Accuracy= 0.92969\n","Iter 1062400, Minibatch Loss= 0.727119, Training Accuracy= 0.93750\n","Iter 1075200, Minibatch Loss= 0.928537, Training Accuracy= 0.92969\n","Iter 1088000, Minibatch Loss= 0.694755, Training Accuracy= 0.91406\n","Iter 1100800, Minibatch Loss= 1.511857, Training Accuracy= 0.92969\n","Iter 1113600, Minibatch Loss= 1.652061, Training Accuracy= 0.91406\n","Iter 1126400, Minibatch Loss= 0.600086, Training Accuracy= 0.96094\n","Iter 1139200, Minibatch Loss= 0.943495, Training Accuracy= 0.95312\n","Iter 1152000, Minibatch Loss= 0.923456, Training Accuracy= 0.92188\n","Iter 1164800, Minibatch Loss= 0.146617, Training Accuracy= 0.96875\n","Iter 1177600, Minibatch Loss= 0.973530, Training Accuracy= 0.94531\n","Iter 1190400, Minibatch Loss= 0.415722, Training Accuracy= 0.93750\n","Iter 1203200, Minibatch Loss= 0.738665, Training Accuracy= 0.94531\n","Iter 1216000, Minibatch Loss= 0.471006, Training Accuracy= 0.94531\n","Iter 1228800, Minibatch Loss= 0.919737, Training Accuracy= 0.94531\n","Iter 1241600, Minibatch Loss= 0.670888, Training Accuracy= 0.97656\n","Iter 1254400, Minibatch Loss= 0.944700, Training Accuracy= 0.95312\n","Iter 1267200, Minibatch Loss= 0.577899, Training Accuracy= 0.93750\n","Iter 1280000, Minibatch Loss= 0.543582, Training Accuracy= 0.96094\n","Iter 1292800, Minibatch Loss= 0.429631, Training Accuracy= 0.95312\n","Iter 1305600, Minibatch Loss= 1.155879, Training Accuracy= 0.92969\n","Iter 1318400, Minibatch Loss= 0.413516, Training Accuracy= 0.96875\n","Iter 1331200, Minibatch Loss= 1.190576, Training Accuracy= 0.93750\n","Iter 1344000, Minibatch Loss= 1.185387, Training Accuracy= 0.94531\n","Iter 1356800, Minibatch Loss= 0.835167, Training Accuracy= 0.96094\n","Iter 1369600, Minibatch Loss= 0.375785, Training Accuracy= 0.95312\n","Iter 1382400, Minibatch Loss= 0.901537, Training Accuracy= 0.95312\n","Iter 1395200, Minibatch Loss= 0.151315, Training Accuracy= 0.98438\n","Iter 1408000, Minibatch Loss= 0.166346, Training Accuracy= 0.97656\n","Iter 1420800, Minibatch Loss= 0.251577, Training Accuracy= 0.96094\n","Iter 1433600, Minibatch Loss= 0.227317, Training Accuracy= 0.96875\n","Iter 1446400, Minibatch Loss= 0.086314, Training Accuracy= 0.98438\n","Iter 1459200, Minibatch Loss= 0.373016, Training Accuracy= 0.97656\n","Iter 1472000, Minibatch Loss= 0.213391, Training Accuracy= 0.97656\n","Iter 1484800, Minibatch Loss= 0.875295, Training Accuracy= 0.96094\n","Iter 1497600, Minibatch Loss= 0.360302, Training Accuracy= 0.96094\n","Iter 1510400, Minibatch Loss= 0.809801, Training Accuracy= 0.96875\n","Iter 1523200, Minibatch Loss= 1.127038, Training Accuracy= 0.93750\n","Iter 1536000, Minibatch Loss= 0.598387, Training Accuracy= 0.94531\n","Iter 1548800, Minibatch Loss= 0.203574, Training Accuracy= 0.96875\n","Iter 1561600, Minibatch Loss= 0.571776, Training Accuracy= 0.94531\n","Iter 1574400, Minibatch Loss= 0.322360, Training Accuracy= 0.94531\n","Iter 1587200, Minibatch Loss= 0.494482, Training Accuracy= 0.94531\n","Iter 1600000, Minibatch Loss= 0.089547, Training Accuracy= 0.98438\n","Iter 1612800, Minibatch Loss= 0.277629, Training Accuracy= 0.96875\n","Iter 1625600, Minibatch Loss= 0.266957, Training Accuracy= 0.96094\n","Iter 1638400, Minibatch Loss= 0.497613, Training Accuracy= 0.93750\n","Iter 1651200, Minibatch Loss= 0.664587, Training Accuracy= 0.94531\n","Iter 1664000, Minibatch Loss= 0.095279, Training Accuracy= 0.99219\n","Iter 1676800, Minibatch Loss= 0.300545, Training Accuracy= 0.96875\n","Iter 1689600, Minibatch Loss= 1.225885, Training Accuracy= 0.95312\n","Iter 1702400, Minibatch Loss= 0.729454, Training Accuracy= 0.95312\n","Iter 1715200, Minibatch Loss= 1.297960, Training Accuracy= 0.92188\n","Iter 1728000, Minibatch Loss= 0.170744, Training Accuracy= 0.96875\n","Iter 1740800, Minibatch Loss= 0.192973, Training Accuracy= 0.97656\n","Iter 1753600, Minibatch Loss= 0.266034, Training Accuracy= 0.97656\n","Iter 1766400, Minibatch Loss= 0.332110, Training Accuracy= 0.95312\n","Iter 1779200, Minibatch Loss= 0.133429, Training Accuracy= 0.98438\n","Iter 1792000, Minibatch Loss= 0.312576, Training Accuracy= 0.96875\n","Iter 1804800, Minibatch Loss= 0.503027, Training Accuracy= 0.96094\n","Iter 1817600, Minibatch Loss= 0.310174, Training Accuracy= 0.96094\n","Iter 1830400, Minibatch Loss= 0.278397, Training Accuracy= 0.97656\n","Iter 1843200, Minibatch Loss= 0.128770, Training Accuracy= 0.96875\n","Iter 1856000, Minibatch Loss= 1.377460, Training Accuracy= 0.95312\n","Iter 1868800, Minibatch Loss= 0.113472, Training Accuracy= 0.96094\n","Iter 1881600, Minibatch Loss= 0.292503, Training Accuracy= 0.97656\n","Iter 1894400, Minibatch Loss= 0.172817, Training Accuracy= 0.95312\n","Iter 1907200, Minibatch Loss= 0.466265, Training Accuracy= 0.96094\n","Iter 1920000, Minibatch Loss= 0.161736, Training Accuracy= 0.97656\n","Iter 1932800, Minibatch Loss= 0.386015, Training Accuracy= 0.98438\n","Iter 1945600, Minibatch Loss= 0.266327, Training Accuracy= 0.96875\n","Iter 1958400, Minibatch Loss= 0.077108, Training Accuracy= 0.96875\n","Iter 1971200, Minibatch Loss= 0.113380, Training Accuracy= 0.98438\n","Iter 1984000, Minibatch Loss= 0.096738, Training Accuracy= 0.97656\n","Iter 1996800, Minibatch Loss= 0.155476, Training Accuracy= 0.95312\n","Iter 2009600, Minibatch Loss= 0.167739, Training Accuracy= 0.96875\n","Iter 2022400, Minibatch Loss= 0.138505, Training Accuracy= 0.96875\n","Iter 2035200, Minibatch Loss= 0.185592, Training Accuracy= 0.94531\n","Iter 2048000, Minibatch Loss= 0.240973, Training Accuracy= 0.98438\n","Iter 2060800, Minibatch Loss= 0.681468, Training Accuracy= 0.93750\n","Iter 2073600, Minibatch Loss= 0.049810, Training Accuracy= 0.96875\n","Iter 2086400, Minibatch Loss= 0.080609, Training Accuracy= 0.98438\n","Iter 2099200, Minibatch Loss= 0.032844, Training Accuracy= 0.99219\n","Iter 2112000, Minibatch Loss= 0.712206, Training Accuracy= 0.94531\n","Iter 2124800, Minibatch Loss= 0.308346, Training Accuracy= 0.95312\n","Iter 2137600, Minibatch Loss= 0.111090, Training Accuracy= 0.98438\n","Iter 2150400, Minibatch Loss= 0.199401, Training Accuracy= 0.96875\n","Iter 2163200, Minibatch Loss= 0.160633, Training Accuracy= 0.96875\n","Iter 2176000, Minibatch Loss= 0.085122, Training Accuracy= 0.98438\n","Iter 2188800, Minibatch Loss= 0.627997, Training Accuracy= 0.94531\n","Iter 2201600, Minibatch Loss= 0.009506, Training Accuracy= 0.99219\n","Iter 2214400, Minibatch Loss= 0.093185, Training Accuracy= 0.96875\n","Iter 2227200, Minibatch Loss= 0.640531, Training Accuracy= 0.95312\n","Iter 2240000, Minibatch Loss= 0.081455, Training Accuracy= 0.99219\n","Iter 2252800, Minibatch Loss= 0.237172, Training Accuracy= 0.96094\n","Iter 2265600, Minibatch Loss= 0.055143, Training Accuracy= 0.98438\n","Iter 2278400, Minibatch Loss= 0.161456, Training Accuracy= 0.97656\n","Iter 2291200, Minibatch Loss= 0.481584, Training Accuracy= 0.95312\n","Iter 2304000, Minibatch Loss= 0.354783, Training Accuracy= 0.98438\n","Iter 2316800, Minibatch Loss= 0.045487, Training Accuracy= 0.98438\n","Iter 2329600, Minibatch Loss= 0.005197, Training Accuracy= 1.00000\n","Iter 2342400, Minibatch Loss= 0.104900, Training Accuracy= 0.96094\n","Iter 2355200, Minibatch Loss= 0.485831, Training Accuracy= 0.96875\n","Iter 2368000, Minibatch Loss= 0.150046, Training Accuracy= 0.96875\n","Iter 2380800, Minibatch Loss= 0.170444, Training Accuracy= 0.97656\n","Iter 2393600, Minibatch Loss= 0.064597, Training Accuracy= 0.97656\n","Iter 2406400, Minibatch Loss= 0.054212, Training Accuracy= 0.97656\n","Iter 2419200, Minibatch Loss= 0.071047, Training Accuracy= 0.96875\n","Iter 2432000, Minibatch Loss= 0.247747, Training Accuracy= 0.95312\n","Iter 2444800, Minibatch Loss= 0.335061, Training Accuracy= 0.96875\n","Iter 2457600, Minibatch Loss= 0.275544, Training Accuracy= 0.94531\n","Iter 2470400, Minibatch Loss= 0.769991, Training Accuracy= 0.96094\n","Iter 2483200, Minibatch Loss= 0.133097, Training Accuracy= 0.96875\n","Iter 2496000, Minibatch Loss= 0.094663, Training Accuracy= 0.98438\n","Iter 2508800, Minibatch Loss= 0.206566, Training Accuracy= 0.97656\n","Iter 2521600, Minibatch Loss= 0.167314, Training Accuracy= 0.96094\n","Iter 2534400, Minibatch Loss= 0.569441, Training Accuracy= 0.97656\n","Iter 2547200, Minibatch Loss= 0.393946, Training Accuracy= 0.97656\n","Iter 2560000, Minibatch Loss= 0.064395, Training Accuracy= 0.98438\n","Iter 2572800, Minibatch Loss= 0.091229, Training Accuracy= 0.98438\n","Iter 2585600, Minibatch Loss= 0.245269, Training Accuracy= 0.96094\n","Iter 2598400, Minibatch Loss= 0.128162, Training Accuracy= 0.98438\n","Iter 2611200, Minibatch Loss= 0.113975, Training Accuracy= 0.96875\n","Iter 2624000, Minibatch Loss= 0.168305, Training Accuracy= 0.97656\n","Iter 2636800, Minibatch Loss= 0.185005, Training Accuracy= 0.96094\n","Iter 2649600, Minibatch Loss= 0.050075, Training Accuracy= 0.99219\n","Iter 2662400, Minibatch Loss= 0.085703, Training Accuracy= 0.96875\n","Iter 2675200, Minibatch Loss= 0.017781, Training Accuracy= 0.99219\n","Iter 2688000, Minibatch Loss= 0.111519, Training Accuracy= 0.97656\n","Iter 2700800, Minibatch Loss= 0.105293, Training Accuracy= 0.99219\n","Iter 2713600, Minibatch Loss= 0.322758, Training Accuracy= 0.97656\n","Iter 2726400, Minibatch Loss= 0.128303, Training Accuracy= 0.97656\n","Iter 2739200, Minibatch Loss= 0.158850, Training Accuracy= 0.98438\n","Iter 2752000, Minibatch Loss= 0.156766, Training Accuracy= 0.97656\n","Iter 2764800, Minibatch Loss= 0.017958, Training Accuracy= 0.99219\n","Iter 2777600, Minibatch Loss= 0.275528, Training Accuracy= 0.97656\n","Iter 2790400, Minibatch Loss= 0.038539, Training Accuracy= 0.99219\n","Iter 2803200, Minibatch Loss= 0.197011, Training Accuracy= 0.96875\n","Iter 2816000, Minibatch Loss= 0.186831, Training Accuracy= 0.96875\n","Iter 2828800, Minibatch Loss= 0.164109, Training Accuracy= 0.97656\n","Iter 2841600, Minibatch Loss= 0.112104, Training Accuracy= 0.96094\n","Iter 2854400, Minibatch Loss= 0.068946, Training Accuracy= 0.96875\n","Iter 2867200, Minibatch Loss= 0.022612, Training Accuracy= 0.99219\n","Iter 2880000, Minibatch Loss= 0.150515, Training Accuracy= 0.99219\n","Iter 2892800, Minibatch Loss= 0.459451, Training Accuracy= 0.96875\n","Iter 2905600, Minibatch Loss= 0.095888, Training Accuracy= 0.98438\n","Iter 2918400, Minibatch Loss= 0.033887, Training Accuracy= 0.99219\n","Iter 2931200, Minibatch Loss= 0.116125, Training Accuracy= 0.98438\n","Iter 2944000, Minibatch Loss= 0.294676, Training Accuracy= 0.97656\n","Iter 2956800, Minibatch Loss= 0.327767, Training Accuracy= 0.95312\n","Iter 2969600, Minibatch Loss= 0.029396, Training Accuracy= 0.98438\n","Iter 2982400, Minibatch Loss= 0.147063, Training Accuracy= 0.99219\n","Iter 2995200, Minibatch Loss= 0.249604, Training Accuracy= 0.96875\n","Optimization Finished!\n","Testing Accuracy: 0.98046875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kot7ljv63gOl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"46f3f98d-4149-430b-8a31-ee4b5a5eb700","executionInfo":{"status":"ok","timestamp":1562919344181,"user_tz":-180,"elapsed":87546,"user":{"displayName":"tamir nave","photoUrl":"https://lh3.googleusercontent.com/-8XBDgRJ8BQ8/AAAAAAAAAAI/AAAAAAAACWs/OaIv-sLVA40/s64/photo.jpg","userId":"00122975368542610629"}}},"source":["import numpy as np\n","print(\"Number of weights: {}\".format(sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Number of weights: 11143\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qGMLDMM4BsGS","colab_type":"code","colab":{}},"source":["sess.close()"],"execution_count":0,"outputs":[]}]}